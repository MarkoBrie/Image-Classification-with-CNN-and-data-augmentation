{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkoBrie/Image-Classification-with-CNN-and-data-augmentation/blob/main/Image_classification_with_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='0'></a>\n",
        "# Sommaire"
      ],
      "metadata": {
        "id": "UzBbYYcRoomI"
      },
      "id": "UzBbYYcRoomI"
    },
    {
      "cell_type": "markdown",
      "id": "dd0693c8",
      "metadata": {
        "id": "dd0693c8"
      },
      "source": [
        "- [ Sommaire](#0)\n",
        "- [ 1 - Configurer le noyau et les dépendances nécessaires](#1)\n",
        "- [ 2 - Préparation du jeu de donnée](#2)\n",
        "  - [ 2.0 - Charger le jeu de donnée CSV avec catégorie](#2.0)\n",
        "  - [ 2.1 - Charger les images](#2.1)\n",
        "  - [ 2.2 - Charger le jeu de donnée CSV avec catégorie](#2.2)\n",
        "  - [ 2.3 - Afficher quelques exemples d'images par catégories](#2.3)\n",
        "- [ 3 - SIFT, Clustering et ARI](#3)\n",
        "  - [ 3.1 - Détermination et affichage des descripteurs SIFT](#3.1)\n",
        "  - [ 3.2 - Classification d'images](#3.2)\n",
        "- [ 4 - Perform Fine-Tuning to Detoxify the Summaries](#4)\n",
        "  - [ 4.1 - Création des features des images](#4.1)\n",
        "  - [ 4.2 - Réduction de dimension et analyse](#4.2)\n",
        "    - [ 4.2.1 - Réduction de dimension avec PCA](#4.2.1)\n",
        "    - [ 4.2.2 - Réduction de dimension T-SNE et affichage des images selon vraies classes](#4.2.1)\n",
        "      \n",
        "  - [ 3.4 - Evaluate the Model Qualitatively](#3.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c857ed0a",
      "metadata": {
        "id": "c857ed0a"
      },
      "source": [
        "<a name='1'></a>\n",
        "# 1 - Configurer le noyau et les dépendances nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bc978375",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc978375",
        "outputId": "280b2951-6a7f-40c1-ae3a-5425bb455624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import os\n",
        "from os import listdir\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve\n",
        "from glob import glob\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalAveragePooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# os.environ[\"TF_KERAS\"]='1'\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bab3c9c",
      "metadata": {
        "id": "8bab3c9c"
      },
      "source": [
        "<a name='2'></a>\n",
        "# 2 Préparation du jeu de donnée"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45e6c063",
      "metadata": {
        "id": "45e6c063"
      },
      "source": [
        "<a name='2.0'></a>\n",
        "## 2.0 Télécharger le jeu de donnée zipped et unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d443505",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d443505",
        "outputId": "29d24784-f936-44e6-e06f-f499e0ecc473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file successfully downloaded and extracted.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "\n",
        "# URL of the zip file\n",
        "zip_url = 'https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/Parcours_data_scientist/Projet+-+Textimage+DAS+V2/Dataset+projet+pre%CC%81traitement+textes+images.zip'\n",
        "\n",
        "# Destination folder to extract the files\n",
        "destination_folder = './'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Download the zip file\n",
        "response = requests.get(zip_url)\n",
        "\n",
        "# Check if the download was successful\n",
        "if response.status_code == 200:\n",
        "    # Unzip the content\n",
        "    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
        "        zip_ref.extractall(destination_folder)\n",
        "    print(\"Zip file successfully downloaded and extracted.\")\n",
        "else:\n",
        "    print(f\"Failed to download the zip file. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18cd03d3",
      "metadata": {
        "id": "18cd03d3"
      },
      "source": [
        "<a name='2.1'></a>\n",
        "## 2.1 Charger les images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ffe1cc7",
      "metadata": {
        "id": "6ffe1cc7"
      },
      "outputs": [],
      "source": [
        "path = \"./Flipkart/Images\"\n",
        "print(path)\n",
        "\n",
        "data_path = os.listdir(path)\n",
        "#print(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb3094a8",
      "metadata": {
        "id": "cb3094a8"
      },
      "source": [
        "<a name='2.2'></a>\n",
        "## 2.2 Charger le jeu de donnée CSV avec catégorie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee523822",
      "metadata": {
        "id": "ee523822"
      },
      "outputs": [],
      "source": [
        "# Specify the path to your CSV file\n",
        "#file_path = './Flipkart/flipkart_com-ecommerce_sample_1050_with_CAT.csv'\n",
        "file_path = './Flipkart/flipkart_com-ecommerce_sample_1050.csv'\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "#print(df.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cat_seperator_fct(sentence):\n",
        "    sentence_clean = sentence.replace('[\"','')\n",
        "    first_cat = sentence_clean.split(\" >> \")[0]\n",
        "    return first_cat\n",
        "\n",
        "df['product_category_tree_1'] = df['product_category_tree'].apply(cat_seperator_fct)\n",
        "df['product_category_tree_1']"
      ],
      "metadata": {
        "id": "aoQTDMF31E_K"
      },
      "id": "aoQTDMF31E_K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887ad362",
      "metadata": {
        "id": "887ad362"
      },
      "outputs": [],
      "source": [
        "# L'éxtraction des noms de catégorie\n",
        "l_cat = list(set(df['product_category_tree_1']))\n",
        "print(\"catégories : \", l_cat)\n",
        "\n",
        "list_labels = l_cat\n",
        "label_no_name = \"no_name \"\n",
        "print('Number of categories : ', len(l_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e2fa09",
      "metadata": {
        "id": "b0e2fa09"
      },
      "outputs": [],
      "source": [
        "df['image_path'] = './Flipkart/Images/' + df['image']\n",
        "df['image_dir'] = './Flipkart/Images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a622382",
      "metadata": {
        "id": "1a622382"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df[\"product_category_tree_1\"])\n",
        "df[\"label\"] = le.transform(df[\"product_category_tree_1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12c972a4",
      "metadata": {
        "id": "12c972a4"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "056aa962",
      "metadata": {
        "id": "056aa962"
      },
      "source": [
        "<a name='2.3'></a>\n",
        "## 2.3 Afficher quelques exemples d'images par catégories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b586eee1",
      "metadata": {
        "id": "b586eee1"
      },
      "outputs": [],
      "source": [
        "from matplotlib.image import imread\n",
        "\n",
        "for name in list_labels :\n",
        "    print(name)\n",
        "    img_test = df[df['product_category_tree_1']==name]['image'][:3]\n",
        "    #img_test\n",
        "    # print(\"-------\")\n",
        "    for i in range(3):\n",
        "        plt.subplot(130 + 1 + i)\n",
        "        #filename = list_fct(name)[i+10]\n",
        "        print(i, ' ', img_test.iloc[i])\n",
        "        filename = './Flipkart/Images/'+img_test.iloc[i]\n",
        "        image = imread(filename)\n",
        "        plt.imshow(image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3'></a>\n",
        "# 3 SIFT, clustering et ARI"
      ],
      "metadata": {
        "id": "4ZJBlXRl1JpR"
      },
      "id": "4ZJBlXRl1JpR"
    },
    {
      "cell_type": "markdown",
      "id": "5114a230",
      "metadata": {
        "id": "5114a230"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "## 3.1 Détermination et affichage des descripteurs SIFT d'un image\n",
        "\n",
        "* L'image contient 319 descripteurs\n",
        "* Chaque descripteur est un vecteur de longueur 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0657c116",
      "metadata": {
        "id": "0657c116"
      },
      "outputs": [],
      "source": [
        "# In order to make xfeatures2d available run the following code\n",
        "#pip install opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f3817c",
      "metadata": {
        "id": "e5f3817c"
      },
      "outputs": [],
      "source": [
        "# Import the OpenCV library\n",
        "import cv2\n",
        "\n",
        "# Create an instance of the SIFT (Scale-Invariant Feature Transform) detector\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "\n",
        "\n",
        "# Read an image from the specified path (using the second image in the list_photos)\n",
        "file = df[\"image_path\"][3]\n",
        "image = cv2.imread(file, 0)  # Convert the image to grayscale\n",
        "image2show = imread(file)\n",
        "plt.imshow(image2show)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Equalize the histogram of the image to enhance contrast\n",
        "image = cv2.equalizeHist(image)\n",
        "\n",
        "# Detect and compute SIFT keypoints and descriptors\n",
        "kp, des = sift.detectAndCompute(image, None)\n",
        "keyp = sift.detect(image, None)\n",
        "\n",
        "# Draw the detected keypoints on the image\n",
        "img = cv2.drawKeypoints(image, keyp, image)\n",
        "\n",
        "# Display the image with keypoints\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# Print information about the computed descriptors\n",
        "print(\"Descripteurs : \", des.shape)\n",
        "print()\n",
        "print(des)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d1b15d3",
      "metadata": {
        "id": "0d1b15d3"
      },
      "source": [
        "<a name='3.2'></a>\n",
        "## 3.2 Classification d'images avec SIFT, bag-of-features et classification supervisée"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b4a722",
      "metadata": {
        "id": "36b4a722"
      },
      "source": [
        "<figure>\n",
        "<img src=\"https://user.oc-static.com/upload/2018/03/13/15209802570047_methode_classif.png\" alt=\"AnVIL Portal Image.\"/>\n",
        "<figure-caption>Figure. Les trois étapes d'un algorithme de classification d'images.</figure-caption>\n",
        "</figure>\n",
        "\n",
        "Etape 1 : Extraction des features. On utilise seulement SIFT pour détecter et décrire les features.  \n",
        "Etape 2 : Création des bag-of-features.  \n",
        "Etape 3 : Classification Supervisée"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f57c99cf",
      "metadata": {
        "id": "f57c99cf"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "## Pré-traitement des images via SIFT\n",
        "### ETAPE 1: Créations des descripteurs de chaque image\n",
        "* Pour chaque image passage en gris et equalisation\n",
        "* création d'une liste de descripteurs par image (\"sift_keypoints_by_img\") qui sera utilisée pour réaliser les histogrammes par image\n",
        "* création d'une liste de descripteurs pour l'ensemble des images (\"sift_keypoints_all\") qui sera utilisé pour créer les clusters de descripteurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1dc75c9",
      "metadata": {
        "id": "d1dc75c9"
      },
      "outputs": [],
      "source": [
        "num_photos = len(df[\"image_path\"])\n",
        "print(\"working on \", num_photos, \" photos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c45b337b",
      "metadata": {
        "id": "c45b337b"
      },
      "outputs": [],
      "source": [
        "# identification of key points and associated descriptors\n",
        "import time, cv2\n",
        "sift_keypoints = []\n",
        "temps1=time.time()\n",
        "sift = cv2.xfeatures2d.SIFT_create(500)\n",
        "\n",
        "for image_num in range(num_photos) :\n",
        "    if image_num%100 == 0 : print(image_num)\n",
        "    image = cv2.imread(df[\"image_path\"][image_num],0) # convert in gray\n",
        "    # image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    res = cv2.equalizeHist(image)   # equalize image histogram\n",
        "    kp, des = sift.detectAndCompute(res, None)\n",
        "    sift_keypoints.append(des)\n",
        "\n",
        "sift_keypoints_by_img = np.asarray(sift_keypoints)\n",
        "sift_keypoints_all    = np.concatenate(sift_keypoints_by_img, axis=0)\n",
        "\n",
        "print()\n",
        "print(\"Nombre de descripteurs : \", sift_keypoints_all.shape)\n",
        "\n",
        "duration1=time.time()-temps1\n",
        "print(\"temps de traitement SIFT descriptor : \", \"%15.2f\" % duration1, \"secondes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b92ed19",
      "metadata": {
        "id": "0b92ed19"
      },
      "source": [
        "## ETAPE 2: Création des clusters de descripteurs (bag-of-features)\n",
        "La création du \"dictionnaire\" des clusters visuels, se réalise en appliquant un algorithme de clustering aux descripteurs de features construits à l'étape 1, comme le k-means. Les visual words correspondent alors aux centres des clusters trouvés.\n",
        "\n",
        "* Utilisation de MiniBatchKMeans pour obtenir des temps de traitement raisonnables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64645cc",
      "metadata": {
        "id": "e64645cc"
      },
      "outputs": [],
      "source": [
        "from sklearn import cluster, metrics\n",
        "\n",
        "# Determination number of clusters\n",
        "temps1=time.time()\n",
        "\n",
        "k = int(round(np.sqrt(len(sift_keypoints_all)),0))\n",
        "print(\"Nombre de clusters estimés : \", k)\n",
        "print(\"Création de\",k, \"clusters de descripteurs ...\")\n",
        "\n",
        "# Clustering\n",
        "kmeans = cluster.MiniBatchKMeans(n_clusters=k, init_size=3*k, random_state=0)\n",
        "kmeans.fit(sift_keypoints_all)\n",
        "\n",
        "duration1=time.time()-temps1\n",
        "print(\"temps de traitement kmeans : \", \"%15.2f\" % duration1, \"secondes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b8ea9f",
      "metadata": {
        "id": "72b8ea9f"
      },
      "source": [
        "## ETAPE 3: CLASSIFICATION SUPERVISEE\n",
        "\n",
        "\n",
        "* Pour chaque image :\n",
        "   - prédiction des numéros de cluster de chaque descripteur\n",
        "   - création d'un histogramme = comptage pour chaque numéro de cluster du nombre de descripteurs de l'image\n",
        "\n",
        "Features d'une image = Histogramme d'une image = Comptage pour une image du nombre de descripteurs par cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e018b9",
      "metadata": {
        "id": "01e018b9"
      },
      "outputs": [],
      "source": [
        "# Creation of histograms (features)\n",
        "temps1=time.time()\n",
        "\n",
        "def build_histogram(kmeans, des, image_num):\n",
        "    res = kmeans.predict(des)\n",
        "    hist = np.zeros(len(kmeans.cluster_centers_))\n",
        "    nb_des=len(des)\n",
        "    if nb_des==0 : print(\"problème histogramme image  : \", image_num)\n",
        "    for i in res:\n",
        "        hist[i] += 1.0/nb_des\n",
        "    return hist\n",
        "\n",
        "\n",
        "# Creation of a matrix of histograms\n",
        "hist_vectors=[]\n",
        "\n",
        "for i, image_desc in enumerate(sift_keypoints_by_img) :\n",
        "    if i%100 == 0 : print(i)\n",
        "    hist = build_histogram(kmeans, image_desc, i) #calculates the histogram\n",
        "    hist_vectors.append(hist) #histogram is the feature vector\n",
        "\n",
        "im_features = np.asarray(hist_vectors)\n",
        "\n",
        "duration1=time.time()-temps1\n",
        "print(\"temps de création histogrammes : \", \"%15.2f\" % duration1, \"secondes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ebd2b2",
      "metadata": {
        "id": "73ebd2b2"
      },
      "source": [
        "## Réductions de dimension\n",
        "### Réduction de dimension PCA\n",
        "* La réduction PCA permet de créer des features décorrélées entre elles, et de diminuer leur dimension, tout en gardant un niveau de variance expliquée élevé (99%)\n",
        "* L'impact est une meilleure séparation des données via le T-SNE et une réduction du temps de traitement du T-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "776f00f7",
      "metadata": {
        "id": "776f00f7"
      },
      "outputs": [],
      "source": [
        "from sklearn import manifold, decomposition\n",
        "\n",
        "print(\"Dimensions dataset avant réduction PCA : \", im_features.shape)\n",
        "pca = decomposition.PCA(n_components=0.99)\n",
        "feat_pca= pca.fit_transform(im_features)\n",
        "print(\"Dimensions dataset après réduction PCA : \", feat_pca.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feb49316",
      "metadata": {
        "id": "feb49316"
      },
      "source": [
        "### Réduction de dimension T-SNE\n",
        "* Réduction de dimension en 2 composantes T-SNE pour affichage en 2D des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d51a346",
      "metadata": {
        "id": "4d51a346"
      },
      "outputs": [],
      "source": [
        "from sklearn import manifold, decomposition\n",
        "\n",
        "tsne = manifold.TSNE(n_components=2, perplexity=30,\n",
        "                     n_iter=2000, init='random', random_state=6)\n",
        "X_tsne = tsne.fit_transform(feat_pca)\n",
        "\n",
        "df_tsne = pd.DataFrame(X_tsne[:,0:2], columns=['tsne1', 'tsne2'])\n",
        "df_tsne[\"class\"] = df[\"product_category_tree_1\"] #data[\"label_name\"]\n",
        "print(df_tsne.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b2fd9d2",
      "metadata": {
        "id": "6b2fd9d2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "sns.scatterplot(\n",
        "    x=\"tsne1\", y=\"tsne2\", hue=\"class\", data=df_tsne, legend=\"brief\",\n",
        "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.6)\n",
        "\n",
        "plt.title('TSNE selon les vraies classes', fontsize = 30, pad = 35, fontweight = 'bold')\n",
        "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
        "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
        "plt.legend(prop={'size': 14})\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e422770",
      "metadata": {
        "id": "3e422770"
      },
      "source": [
        "## Analyse mesures : similarité entre catégories et clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baa71fca",
      "metadata": {
        "id": "baa71fca"
      },
      "outputs": [],
      "source": [
        "from sklearn import cluster, metrics\n",
        "\n",
        "cls = cluster.KMeans(n_clusters=7, random_state=6)\n",
        "cls.fit(X_tsne)\n",
        "\n",
        "df_tsne[\"cluster\"] = cls.labels_\n",
        "print(df_tsne.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bf7c32f",
      "metadata": {
        "id": "3bf7c32f"
      },
      "source": [
        "###  Affichage des images selon clusters et calcul ARI de similarité catégories images / clusters\n",
        "* Le score ARI de 0.03 est très faible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7560057",
      "metadata": {
        "id": "e7560057"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(\n",
        "    x=\"tsne1\", y=\"tsne2\",\n",
        "    hue=\"cluster\",\n",
        "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.6,\n",
        "    data=df_tsne,\n",
        "    legend=\"brief\")\n",
        "\n",
        "plt.title('TSNE selon les clusters', fontsize = 30, pad = 35, fontweight = 'bold')\n",
        "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
        "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
        "plt.legend(prop={'size': 14})\n",
        "\n",
        "plt.show()\n",
        "\n",
        "labels = df[\"label\"]\n",
        "print(\"ARI : \", metrics.adjusted_rand_score(labels, cls.labels_))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cef6a89",
      "metadata": {
        "id": "4cef6a89"
      },
      "source": [
        "### Analyse par classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "697fd42c",
      "metadata": {
        "id": "697fd42c"
      },
      "outputs": [],
      "source": [
        "df_tsne.groupby(\"cluster\").count()[\"class\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbdd7e3e",
      "metadata": {
        "id": "dbdd7e3e"
      },
      "outputs": [],
      "source": [
        "conf_mat = metrics.confusion_matrix(labels, cls.labels_)\n",
        "print(conf_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edbad595",
      "metadata": {
        "id": "edbad595"
      },
      "outputs": [],
      "source": [
        "def conf_mat_transform(y_true,y_pred) :\n",
        "    conf_mat = metrics.confusion_matrix(y_true,y_pred)\n",
        "\n",
        "    # corresp = np.argmax(conf_mat, axis=0)\n",
        "    corresp = [6, 5, 4, 3, 1, 2, 0]\n",
        "    print (\"Correspondance des clusters : \", corresp)\n",
        "    # y_pred_transform = np.apply_along_axis(correspond_fct, 1, y_pred)\n",
        "    labels = pd.Series(y_true, name=\"y_true\").to_frame()\n",
        "    labels['y_pred'] = y_pred\n",
        "    labels['y_pred_transform'] = labels['y_pred'].apply(lambda x : corresp[x])\n",
        "\n",
        "    return labels['y_pred_transform']\n",
        "\n",
        "cls_labels_transform = conf_mat_transform(labels, cls.labels_)\n",
        "conf_mat = metrics.confusion_matrix(labels, cls_labels_transform)\n",
        "print(conf_mat)\n",
        "print()\n",
        "print(metrics.classification_report(labels, cls_labels_transform))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07a8617d",
      "metadata": {
        "id": "07a8617d"
      },
      "outputs": [],
      "source": [
        "df_cm = pd.DataFrame(conf_mat, index = [label for label in list_labels],\n",
        "                  columns = [i for i in \"0123456\"])\n",
        "plt.figure(figsize = (6,4))\n",
        "sns.heatmap(df_cm, annot=True, cmap=\"Blues\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5862ed1",
      "metadata": {
        "id": "b5862ed1"
      },
      "source": [
        "<a name='4'></a>\n",
        "# 4 Etape 1 : étude de faisabilité d'une classification supervisée\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4.0'></a>\n",
        "## 4.0 Création du modéle préentrainé basé sur un VGG16"
      ],
      "metadata": {
        "id": "CADwy7Gi0Qf8"
      },
      "id": "CADwy7Gi0Qf8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a98341",
      "metadata": {
        "scrolled": true,
        "id": "c7a98341"
      },
      "outputs": [],
      "source": [
        "# Import the VGG16 model, a pre-trained convolutional neural network for image classification.\n",
        "# The model is imported from the Keras applications module.\n",
        "base_model = VGG16()\n",
        "\n",
        "# Create a new model that takes the same inputs as the VGG16 model\n",
        "# but outputs the second-to-last layer's output (penultimate layer)\n",
        "model = Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)\n",
        "\n",
        "# Print a summary of the architecture and parameters of the newly created model\n",
        "#print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cb4881b",
      "metadata": {
        "id": "4cb4881b"
      },
      "source": [
        "<a name='4.1'></a>\n",
        "## 4.1 Création des features des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e32a343e",
      "metadata": {
        "id": "e32a343e"
      },
      "outputs": [],
      "source": [
        "# Create an empty list to store the extracted features from images\n",
        "images_features = []\n",
        "\n",
        "# Initialize a counter for tracking progress\n",
        "i = 0\n",
        "\n",
        "# Iterate through each image file path in the \"image_path\" column of the \"data\" DataFrame\n",
        "for image_file in df[\"image_path\"]:\n",
        "    # Print progress every 100 images\n",
        "    if i % 100 == 0:\n",
        "        print(i)\n",
        "\n",
        "    # Increment the counter\n",
        "    i += 1\n",
        "\n",
        "    # Load the image, resizing it to the target size of (224, 224)\n",
        "    image = load_img(image_file, target_size=(224, 224))\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    # Add an extra dimension to the image array to match the input shape expected by the model\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Preprocess the image data to align with the preprocessing used during training the model\n",
        "    image = preprocess_input(image)\n",
        "\n",
        "    # Use the pre-trained model to predict features from the preprocessed image\n",
        "    # Append the predicted features to the list\n",
        "    images_features.append(model.predict(image, verbose=0)[0])\n",
        "\n",
        "# Convert the list of image features to a numpy array\n",
        "images_features = np.asarray(images_features)\n",
        "\n",
        "# Print the shape of the resulting array (number of images x number of features)\n",
        "print(images_features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ae10ee2",
      "metadata": {
        "id": "9ae10ee2"
      },
      "source": [
        "<a name='4.2'></a>\n",
        "## 4.2 Réduction dimension et analyse"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37bdc675",
      "metadata": {
        "id": "37bdc675"
      },
      "source": [
        "<a name='4.2.1'></a>\n",
        "### 4.2.1 Réduction de dimension PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f7122a7",
      "metadata": {
        "id": "5f7122a7"
      },
      "outputs": [],
      "source": [
        "from sklearn import manifold, decomposition\n",
        "\n",
        "print(images_features.shape)\n",
        "pca = decomposition.PCA(n_components=0.99)\n",
        "feat_pca= pca.fit_transform(images_features)\n",
        "print(feat_pca.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1555dd87",
      "metadata": {
        "id": "1555dd87"
      },
      "source": [
        "<a name='4.2.2'></a>\n",
        "### 4.2.2 Réduction de dimension T-SNE et affichage des images selon vraies classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ec744e",
      "metadata": {
        "id": "96ec744e"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "temps1 = time.time()\n",
        "\n",
        "tsne = manifold.TSNE(n_components=2, perplexity=30, n_iter=2000, init='random', random_state=6)\n",
        "X_tsne = tsne.fit_transform(feat_pca)\n",
        "\n",
        "duration1=time.time()-temps1\n",
        "print(\"temps de T-SNE : \", \"%15.2f\" % duration1, \"secondes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e83e5f",
      "metadata": {
        "id": "71e83e5f"
      },
      "outputs": [],
      "source": [
        "df_tsne = pd.DataFrame(X_tsne, columns=['tsne1', 'tsne2'])\n",
        "df_tsne[\"class\"] = df['product_category_tree_1'] # data[\"label_name\"]\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.scatterplot(\n",
        "    x=\"tsne1\", y=\"tsne2\",\n",
        "    hue=\"class\",\n",
        "    palette=sns.color_palette('tab10', n_colors=7), s=50, alpha=0.6,\n",
        "    data=df_tsne,\n",
        "    legend=\"brief\")\n",
        "\n",
        "plt.title('TSNE selon les vraies classes', fontsize = 30, pad = 35, fontweight = 'bold')\n",
        "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
        "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
        "plt.legend(prop={'size': 14})\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76bac4c6",
      "metadata": {
        "id": "76bac4c6"
      },
      "source": [
        "todo kmeans + ari"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e329b54d",
      "metadata": {
        "id": "e329b54d"
      },
      "source": [
        "<a name='5'></a>\n",
        "# 5 Etape 2 : Classification Supervisée\n",
        "4 approches sont présentées :\n",
        "* 1 Une approche simple par préparation initiale de l'ensemble des images avant classification supervisée avec un CNN\n",
        "* 2 Une approche par data generator, permettant facilement la data augmentation. Les images sont directement récupérées à la volée dans le repertoire des images\n",
        "* 3 Une approche récente proposée par Tensorflow.org par DataSet, sans data augmentation\n",
        "* 4 Une approche par  DataSet, avec data augmentation intégrée au modèle : layer en début de modèle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f891ad5b",
      "metadata": {
        "id": "f891ad5b"
      },
      "source": [
        "<a name='5.0'></a>\n",
        "## 5.0 Création du modèle de classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65dec2bb",
      "metadata": {
        "id": "65dec2bb"
      },
      "outputs": [],
      "source": [
        "# Define a function to create a custom model based on VGG16\n",
        "def create_model_fct():\n",
        "    # Retrieve a pre-trained VGG16 model without the top classification layer\n",
        "    model0 = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
        "\n",
        "    # Set all layers of the pre-trained model to non-trainable\n",
        "    for layer in model0.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Get the output of the pre-trained model\n",
        "    x = model0.output\n",
        "\n",
        "\n",
        "    # Add additional layers to the model\n",
        "    # Part of the network that does the classification\n",
        "    x = GlobalAveragePooling2D()(x)  # Global average pooling layer\n",
        "    x = Dense(256, activation='relu')(x)  # Fully connected layer with ReLU activation\n",
        "    x = Dropout(0.5)(x)  # Dropout layer to reduce overfitting\n",
        "    predictions = Dense(7, activation='softmax')(x)  # Output layer with softmax activation\n",
        "\n",
        "    # Define the new model with the added layers\n",
        "    model = Model(inputs=model0.input, outputs=predictions)\n",
        "\n",
        "    # Compile the model with categorical crossentropy loss, rmsprop optimizer, and accuracy metric\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])\n",
        "\n",
        "    # Print a summary of the model architecture\n",
        "    print(model.summary())\n",
        "\n",
        "    # Return the created model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics\n",
        "\n",
        "# Step 1: Initialize an empty DataFrame\n",
        "columns = ['Method', 'Training_Accuracy', 'Validation_Accuracy']\n",
        "CNN_methods_accuracy = pd.DataFrame(columns=columns)"
      ],
      "metadata": {
        "id": "TGvqxG_Wzhv2"
      },
      "id": "TGvqxG_Wzhv2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "92aa2d12",
      "metadata": {
        "id": "92aa2d12"
      },
      "source": [
        "<a name='5.1'></a>\n",
        "## 5.1 Approche préparation initiale des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e05fc85",
      "metadata": {
        "id": "2e05fc85"
      },
      "outputs": [],
      "source": [
        "# Specify the fraction of data to allocate to the second part (e.g., 0.2 for 20%)\n",
        "test_size = 0.2\n",
        "\n",
        "# Use train_test_split to randomly split the DataFrame\n",
        "df_train, df_test = train_test_split(df, test_size=test_size, random_state=42)\n",
        "\n",
        "df_train.reset_index(inplace=True)\n",
        "df_test.reset_index(inplace=True)\n",
        "# Display the shapes of the two parts\n",
        "print(\"Shape of Part 1:\", df_train.shape)\n",
        "print(\"Shape of Part 2:\", df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a730ace4",
      "metadata": {
        "id": "a730ace4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8f2e1a6",
      "metadata": {
        "id": "e8f2e1a6"
      },
      "outputs": [],
      "source": [
        "def image_prep_fct(data) :\n",
        "    prepared_images = []\n",
        "    for image_num in range(len(data['image_path'])) :\n",
        "        img = (load_img(\n",
        "            data['image_path'][image_num],\n",
        "            target_size=(224, 224)))\n",
        "        img = img_to_array(img)\n",
        "        img = img.reshape((img.shape[0], img.shape[1], img.shape[2]))\n",
        "        img = preprocess_input(img)\n",
        "        prepared_images.append(img)\n",
        "        prepared_images_np = np.array(prepared_images)\n",
        "    return prepared_images_np\n",
        "\n",
        "images_np = image_prep_fct(df_train)\n",
        "print(images_np.shape)\n",
        "images_np_test = image_prep_fct(df_test)\n",
        "print(images_np_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bfe50b9",
      "metadata": {
        "id": "6bfe50b9"
      },
      "outputs": [],
      "source": [
        "df_train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c830c2d",
      "metadata": {
        "id": "1c830c2d"
      },
      "outputs": [],
      "source": [
        "X = images_np\n",
        "y = to_categorical(df_train['label'])\n",
        "\n",
        "X_test = images_np_test\n",
        "y_test = to_categorical(df_test['label'])\n",
        "\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05bde749",
      "metadata": {
        "id": "05bde749"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520f059d",
      "metadata": {
        "scrolled": true,
        "id": "520f059d"
      },
      "outputs": [],
      "source": [
        "# Création du modèle\n",
        "with tf.device('/gpu:0'):\n",
        "    model1 = create_model_fct()\n",
        "\n",
        "# Création du callback\n",
        "model1_save_path1 = \"./Output/model1_best_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(model1_save_path1, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "callbacks_list = [checkpoint, es]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e3ca98c",
      "metadata": {
        "id": "0e3ca98c"
      },
      "outputs": [],
      "source": [
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "052b9a36",
      "metadata": {
        "scrolled": true,
        "id": "052b9a36"
      },
      "outputs": [],
      "source": [
        "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
        "with tf.device('/gpu:0'):\n",
        "    history1 = model1.fit(X_train, y_train, epochs=50, batch_size=64,\n",
        "                       callbacks=callbacks_list, validation_data=(X_val, y_val), verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de6f00f",
      "metadata": {
        "id": "0de6f00f"
      },
      "outputs": [],
      "source": [
        "# Score du dernier epoch\n",
        "\n",
        "loss, train_accuracy = model1.evaluate(X_train, y_train, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "print()\n",
        "loss, val_accuracy = model1.evaluate(X_val, y_val, verbose=True)\n",
        "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "new_values = {'Method': '1 base', 'Training_Accuracy': train_accuracy, 'Validation_Accuracy': val_accuracy}\n",
        "CNN_methods_accuracy = CNN_methods_accuracy.append(new_values, ignore_index=True)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56551dcf",
      "metadata": {
        "id": "56551dcf"
      },
      "outputs": [],
      "source": [
        "# Score de l'epoch optimal\n",
        "\n",
        "model1.load_weights(model1_save_path1)\n",
        "\n",
        "loss, accuracy = model1.evaluate(X_val, y_val, verbose=False)\n",
        "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
        "\n",
        "loss, accuracy = model1.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Test Accuracy       :  {:.4f}\".format(accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ebfadeb",
      "metadata": {
        "id": "6ebfadeb"
      },
      "outputs": [],
      "source": [
        "#pip install plot_keras_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba9d696f",
      "metadata": {
        "id": "ba9d696f"
      },
      "outputs": [],
      "source": [
        "from plot_keras_history import show_history, plot_history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "show_history(history1)\n",
        "plot_history(history1, path=\"standard.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e89ba6",
      "metadata": {
        "id": "c5e89ba6"
      },
      "outputs": [],
      "source": [
        "y_val_num = np.argmax(y_val, axis=1)\n",
        "y_val_pred = np.argmax(model1.predict(X_val), axis=1)\n",
        "y_val_num = np.argmax(y_val, axis=1)\n",
        "print(y_val_num)\n",
        "print()\n",
        "print(y_val_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f85c0a",
      "metadata": {
        "id": "24f85c0a"
      },
      "outputs": [],
      "source": [
        "conf_mat = metrics.confusion_matrix(y_val_num, y_val_pred)\n",
        "print(conf_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ea835a5",
      "metadata": {
        "id": "1ea835a5"
      },
      "outputs": [],
      "source": [
        "y_val_pred_transform = conf_mat_transform(y_val_num, y_val_pred)\n",
        "conf_mat = metrics.confusion_matrix(y_val_num, y_val_pred_transform)\n",
        "print(conf_mat)\n",
        "print()\n",
        "print(metrics.classification_report(y_val_num, y_val_pred_transform))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a62de61d",
      "metadata": {
        "id": "a62de61d"
      },
      "outputs": [],
      "source": [
        "df_cm = pd.DataFrame(conf_mat, index = [label for label in list_labels],\n",
        "                  columns = [i for i in \"0123456\"])\n",
        "plt.figure(figsize = (6,7))\n",
        "sns.heatmap(df_cm, annot=True, cmap=\"Blues\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee2934be",
      "metadata": {
        "id": "ee2934be"
      },
      "source": [
        "<a name='5.2'></a>\n",
        "## 5.2 Approche ImageDatagenerator avec data augmentation\n",
        "\n",
        "CF https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow (noté désormais comme \"deprecated\", incite à utiiser l'approche suivante)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee0f0f6d",
      "metadata": {
        "id": "ee0f0f6d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879f073a",
      "metadata": {
        "id": "879f073a"
      },
      "outputs": [],
      "source": [
        "# Pour mélanger les images, classées initalement par classe\n",
        "data = df.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbeff975",
      "metadata": {
        "id": "dbeff975"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "def data_flow_fct(data, datagen, data_type=None) :\n",
        "    data_flow = datagen.flow_from_dataframe(data, directory='',\n",
        "                                x_col='image_path', y_col='product_category_tree_1',\n",
        "                                weight_col=None, target_size=(256, 256),\n",
        "                                classes=None, class_mode='categorical',\n",
        "                                batch_size=batch_size, shuffle=True, seed=42,\n",
        "                                subset=data_type\n",
        "                                )\n",
        "    return data_flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6baead89",
      "metadata": {
        "scrolled": true,
        "id": "6baead89"
      },
      "outputs": [],
      "source": [
        "datagen_train = ImageDataGenerator(\n",
        "#    featurewise_center=True,\n",
        "#    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.25,\n",
        "    preprocessing_function=preprocess_input)\n",
        "\n",
        "train_flow = data_flow_fct(data, datagen_train, data_type='training')\n",
        "val_flow = data_flow_fct(data, datagen_train, data_type='validation')\n",
        "\n",
        "datagen_test = ImageDataGenerator(\n",
        "    validation_split=0,\n",
        "    preprocessing_function=preprocess_input)\n",
        "\n",
        "test_flow = data_flow_fct(df_test, datagen_test, data_type=None)\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "# datagen.fit(X_train)\n",
        "# fits the model on batches with real-time data augmentation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8689e5f",
      "metadata": {
        "scrolled": true,
        "id": "e8689e5f"
      },
      "outputs": [],
      "source": [
        "# Création du modèle\n",
        "with tf.device('/gpu:0'):\n",
        "    model2 = create_model_fct()\n",
        "\n",
        "# Création du callback\n",
        "model2_save_path = \"./model2_best_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(model2_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "callbacks_list = [checkpoint, es]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "758d659b",
      "metadata": {
        "scrolled": true,
        "id": "758d659b"
      },
      "outputs": [],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c254515",
      "metadata": {
        "scrolled": true,
        "id": "3c254515"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    history2 = model2.fit(train_flow,\n",
        "                    validation_data=val_flow,\n",
        "                    batch_size=batch_size, epochs=50, callbacks=callbacks_list, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71613c55",
      "metadata": {
        "scrolled": true,
        "id": "71613c55"
      },
      "outputs": [],
      "source": [
        "# Score du dernier epoch\n",
        "\n",
        "loss, accuracy = model2.evaluate(train_flow, verbose=True)\n",
        "print(\"Training Accuracy   : {:.4f}\".format(accuracy))\n",
        "print()\n",
        "loss, accuracy = model2.evaluate(val_flow, verbose=True)\n",
        "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6b8aa96",
      "metadata": {
        "id": "e6b8aa96"
      },
      "outputs": [],
      "source": [
        "# Score de l'epoch optimal\n",
        "\n",
        "model2.load_weights(model2_save_path)\n",
        "\n",
        "loss, accuracy = model2.evaluate(val_flow, verbose=False)\n",
        "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
        "\n",
        "loss, accuracy = model2.evaluate(test_flow, verbose=False)\n",
        "print(\"Test Accuracy       :  {:.4f}\".format(accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a13b2f",
      "metadata": {
        "scrolled": true,
        "id": "78a13b2f"
      },
      "outputs": [],
      "source": [
        "from plot_keras_history import show_history, plot_history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "show_history(history2)\n",
        "plot_history(history2, path=\"standard.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be563ff9",
      "metadata": {
        "id": "be563ff9"
      },
      "source": [
        "<a name='5.3'></a>\n",
        "## 5.3 Approche nouvelle par Dataset sans data augmentation\n",
        "\n",
        "CF https://www.tensorflow.org/tutorials/load_data/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb5f18b",
      "metadata": {
        "id": "cbb5f18b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import module\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf5c8794",
      "metadata": {
        "id": "cf5c8794"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "def dataset_fct(path, validation_split=0, data_type=None) :\n",
        "    print(path)\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "                    path,\n",
        "                    labels='inferred', label_mode='categorical',\n",
        "                    #class_names=None,\n",
        "                    batch_size=32, image_size=(224, 224), shuffle=True, seed=42,\n",
        "                    validation_split=validation_split, subset=data_type\n",
        "                    )\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1be74b21",
      "metadata": {
        "id": "1be74b21"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    os.mkdir('./Flipkart/TRAIN')\n",
        "except OSError as error:\n",
        "    print(error)\n",
        "\n",
        "for i in class_folder_name:\n",
        "    #print(i)\n",
        "    try:\n",
        "        os.mkdir('./Flipkart/TRAIN/'+str(i))\n",
        "    except OSError as error:\n",
        "        print(error)\n",
        "\n",
        "for i in range(df_train.shape[0]):\n",
        "    #print(\"i \", i)\n",
        "    # copy the contents of the\n",
        "    shutil.copyfile(df_train['image_path'][i], './Flipkart/TRAIN/'+df_train['product_category_tree_1'][i]+'/'+df_train['image'][i])\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d432178f",
      "metadata": {
        "id": "d432178f"
      },
      "outputs": [],
      "source": [
        "class_folder_name = set(df['product_category_tree_1'])\n",
        "\n",
        "try:\n",
        "    os.mkdir('./Flipkart/TEST')\n",
        "except OSError as error:\n",
        "    print(error)\n",
        "\n",
        "for i in class_folder_name:\n",
        "    print(i)\n",
        "    try:\n",
        "        os.mkdir('./Flipkart/TEST/'+str(i))\n",
        "    except OSError as error:\n",
        "        print(error)\n",
        "\n",
        "for i in range(df_test.shape[0]):\n",
        "    #print(\"i \", i)\n",
        "    # copy the contents of the\n",
        "    shutil.copyfile(df_test['image_path'][i], './Flipkart/TEST/'+df_test['product_category_tree_1'][i]+'/'+df_test['image'][i])\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5335625",
      "metadata": {
        "id": "f5335625"
      },
      "outputs": [],
      "source": [
        "path_train = './Flipkart/TRAIN/'\n",
        "path_test = './Flipkart/TEST/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3ca139",
      "metadata": {
        "scrolled": true,
        "id": "cf3ca139"
      },
      "outputs": [],
      "source": [
        "dataset_train = dataset_fct(path_train, validation_split=0.25, data_type='training')\n",
        "dataset_val = dataset_fct(path_train, validation_split=0.25, data_type='validation')\n",
        "dataset_test = dataset_fct(path_test, validation_split=0, data_type=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53360877",
      "metadata": {
        "id": "53360877"
      },
      "outputs": [],
      "source": [
        "\n",
        "class_names = dataset_test.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee117458",
      "metadata": {
        "id": "ee117458"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(class_names)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in dataset_test.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        # Convert the labels tensor to a NumPy array and then use it as an index\n",
        "        label_index = tf.argmax(labels[i]).numpy()\n",
        "        print(labels[i], 'label index ',label_index)\n",
        "        plt.title(class_names[label_index])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a7bfacf",
      "metadata": {
        "scrolled": true,
        "id": "3a7bfacf"
      },
      "outputs": [],
      "source": [
        "# Création du modèle\n",
        "with tf.device('/gpu:0'):\n",
        "    model3 = create_model_fct()\n",
        "\n",
        "# Création du callback\n",
        "model3_save_path = \"./model3_best_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(model3_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "callbacks_list = [checkpoint, es]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ee424d",
      "metadata": {
        "id": "f8ee424d"
      },
      "outputs": [],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d1952f",
      "metadata": {
        "scrolled": false,
        "id": "c1d1952f"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    history3 = model3.fit(dataset_train,\n",
        "                    validation_data=dataset_val,\n",
        "                    batch_size=batch_size, epochs=50, callbacks=callbacks_list, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10963802",
      "metadata": {
        "scrolled": false,
        "id": "10963802"
      },
      "outputs": [],
      "source": [
        "# Score du dernier epoch\n",
        "\n",
        "loss, accuracy = model3.evaluate(dataset_train, verbose=True)\n",
        "print(\"Training Accuracy   : {:.4f}\".format(accuracy))\n",
        "print()\n",
        "loss, accuracy = model3.evaluate(dataset_val, verbose=True)\n",
        "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff59bc01",
      "metadata": {
        "scrolled": true,
        "id": "ff59bc01"
      },
      "outputs": [],
      "source": [
        "# Score de l'epoch optimal\n",
        "\n",
        "model3.load_weights(model3_save_path)\n",
        "\n",
        "loss, accuracy = model3.evaluate(dataset_val, verbose=False)\n",
        "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
        "\n",
        "loss, accuracy = model3.evaluate(dataset_test, verbose=False)\n",
        "print(\"Test Accuracy       :  {:.4f}\".format(accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5a616c",
      "metadata": {
        "scrolled": true,
        "id": "5a5a616c"
      },
      "outputs": [],
      "source": [
        "from plot_keras_history import show_history, plot_history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "show_history(history3)\n",
        "plot_history(history3, path=\"standard.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3ba0e28",
      "metadata": {
        "id": "a3ba0e28"
      },
      "source": [
        "\n",
        "## 4.4 Approche nouvelle par Dataset avec data augmentation intégrée au modèle\n",
        "\n",
        "CF https://www.tensorflow.org/tutorials/images/data_augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a4c1c08",
      "metadata": {
        "id": "2a4c1c08"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "def dataset_fct(path, validation_split=0, data_type=None) :\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "                    path, labels='inferred', label_mode='categorical',\n",
        "                    class_names=None,\n",
        "                    batch_size=batch_size, image_size=(224, 224), shuffle=True, seed=42,\n",
        "                    validation_split=validation_split, subset=data_type\n",
        "                    )\n",
        "    return dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e35de55f",
      "metadata": {
        "id": "e35de55f"
      },
      "outputs": [],
      "source": [
        "#dataset_train = dataset_fct(path_train, validation_split=0.25, data_type='training')\n",
        "#dataset_val = dataset_fct(path_train, validation_split=0.25, data_type='validation')\n",
        "#dataset_test = dataset_fct(path_test, validation_split=0, data_type=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "595110f1",
      "metadata": {
        "id": "595110f1"
      },
      "outputs": [],
      "source": [
        "def resize_and_rescale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    image = (image / 255.0)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e7a3dfa",
      "metadata": {
        "id": "0e7a3dfa"
      },
      "outputs": [],
      "source": [
        "def create_model_fct2() :\n",
        "    # Data augmentation\n",
        "    data_augmentation = Sequential([\n",
        "        RandomFlip(\"horizontal\", input_shape=(224, 224, 3)),\n",
        "        RandomRotation(0.1),\n",
        "        RandomZoom(0.1),\n",
        "        # Rescaling(1./127.5, offset=-1.0)\n",
        "      ])\n",
        "\n",
        "    # Récupération modèle pré-entraîné\n",
        "    model_base = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
        "    for layer in model_base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Définition du nouveau modèle\n",
        "    model = Sequential([\n",
        "                data_augmentation,\n",
        "                Rescaling(1./127.5, offset=-1),\n",
        "                model_base,\n",
        "                GlobalAveragePooling2D(),\n",
        "                Dense(256, activation='relu'),\n",
        "                Dropout(0.5),\n",
        "                Dense(7, activation='softmax')\n",
        "                ])\n",
        "\n",
        "    # compilation du modèle\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Création du modèle\n",
        "with tf.device('/gpu:0'):\n",
        "    model4 = create_model_fct2()\n",
        "\n",
        "# Création du callback\n",
        "model4_save_path = \"./model4_best_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(model4_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "callbacks_list = [checkpoint, es]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "416ee7f3",
      "metadata": {
        "id": "416ee7f3"
      },
      "outputs": [],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb2ceb51",
      "metadata": {
        "id": "bb2ceb51"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    history4 = model4.fit(dataset_train,\n",
        "                    validation_data=dataset_val,\n",
        "                    batch_size=batch_size, epochs=50, callbacks=callbacks_list, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b764766",
      "metadata": {
        "scrolled": true,
        "id": "3b764766"
      },
      "outputs": [],
      "source": [
        "# Score du dernier epoch\n",
        "\n",
        "loss, accuracy = model4.evaluate(dataset_train, verbose=True)\n",
        "print(\"Training Accuracy   : {:.4f}\".format(accuracy))\n",
        "print()\n",
        "loss, accuracy = model4.evaluate(dataset_val, verbose=True)\n",
        "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b0acd7b",
      "metadata": {
        "scrolled": true,
        "id": "5b0acd7b"
      },
      "outputs": [],
      "source": [
        "# Score de l'epoch optimal\n",
        "\n",
        "model4.load_weights(model4_save_path)\n",
        "\n",
        "loss, accuracy = model4.evaluate(dataset_val, verbose=False)\n",
        "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
        "\n",
        "loss, accuracy = model4.evaluate(dataset_test, verbose=False)\n",
        "print(\"Test Accuracy       :  {:.4f}\".format(accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb37679b",
      "metadata": {
        "scrolled": true,
        "id": "cb37679b"
      },
      "outputs": [],
      "source": [
        "# Score du dernier epoch\n",
        "\n",
        "loss, accuracy = model4.evaluate(dataset_train, verbose=True)\n",
        "print(\"Training Accuracy   : {:.4f}\".format(accuracy))\n",
        "print()\n",
        "loss, accuracy = model4.evaluate(dataset_val, verbose=True)\n",
        "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c77c34",
      "metadata": {
        "scrolled": true,
        "id": "66c77c34"
      },
      "outputs": [],
      "source": [
        "# Score de l'epoch optimal\n",
        "\n",
        "model4.load_weights(model4_save_path)\n",
        "\n",
        "loss, accuracy = model4.evaluate(dataset_val, verbose=False)\n",
        "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
        "\n",
        "loss, accuracy = model4.evaluate(dataset_test, verbose=False)\n",
        "print(\"Test Accuracy       :  {:.4f}\".format(accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b2e288",
      "metadata": {
        "id": "11b2e288"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf938a0e",
      "metadata": {
        "id": "bf938a0e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "18cd03d3",
        "cb3094a8",
        "5114a230",
        "0b92ed19",
        "72b8ea9f",
        "73ebd2b2",
        "3e422770",
        "3bf7c32f",
        "4cef6a89",
        "37bdc675",
        "1555dd87"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}